---
title: "Lab 4"
author: "Lucas Vieira"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
```

## Lendo os dados de treino e teste
```{r}
train <- read.csv("train.csv")
test <- read.csv("test.csv")
```

## Removendo variáveis categóricas dos dados de treino, pois são irrelevantes para a regressão
```{r}
train <- train %>% select(-nome, -uf, -estado_civil, 
                          -partido, -ocupacao,-ano, 
                          -cargo,-grau,-sexo, 
                          -sequencial_candidato)
```

## Usando regrassão ridge para treinar o modelo
```{r}
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

# modelo utilizando regressão ridge
model <- train(votos ~ ., 
               data = train,
               method = "ridge",
               trControl = fitControl,
               preProcess = c('scale', 'center'),
               tuneGrid = lambdaGrid,
               na.action = na.omit)

plot(model)
```

## Usando regrassão lasso para treinar o modelo.

```{r}
lambda <- expand.grid(fraction = seq(0.01, 10^-8, length=20))

model_lasso <- train(votos ~ ., 
                     data = train, 
                     method = "lasso", 
                     tuneGrid = lambda,
                     preProc = c("center", "scale"),
                     trControl = fitControl)

plot(model_lasso)
```


## Usando regrassão KNN para treinar o modelo.

```{r}
k <- expand.grid(k = seq(20, 100, length=81))
model_knn <- train(votos ~ ., 
                     data = train, 
                     method = "knn", 
                     tuneGrid = k,
                     preProc = c("center", "scale"),
                     trControl = fitControl)

plot(model_knn)
```


## Comparação dos três modelos em termos do erro RMSE de validação cruzada

```{r}
summary(resamples(list(RIDGE = model, LASSO = model_lasso, KNN = model_knn)))
```

Pelo sumário acima, podemos notar que o KNN possui o menor RMSE entre as regressões Ridge e Lasso. Isso mostra que o KNN é um bom modelo para representar os dados.

## Importância das variáveis
```{r}
ggplot(varImp(model)) + ggtitle("Ridge - Impostância das Variáveis") + theme_bw()
```
```{r}
ggplot(varImp(model_lasso)) + ggtitle("Lasso - Impostância das Variáveis") + theme_bw()
```

```{r}
predictors <- predictors(model_lasso)
predictors
```

Tanto para o modelo de regressão Ridge quando para o Lasso, as variáveis *total_receita*, *toral_despesa* e *recursos_de_pessoas_juridicas* são as mais importantes como mostra os gráficos de barra acima. No modelo Lasso todas as outras variáveis foram descartadas, exceto *recursos_de_pessoas_fisicas*, *recursos_de_pessoas_juridicas* e *total_despesa*.

## Re-treinando KNN com variáveis mais importante segundo o modelo Lasso
```{r}
filteredTrain <- train %>% 
         select(predictors, votos)

model_knn <- train(votos ~ ., 
                     data = filteredTrain, 
                     method = "knn", 
                     tuneGrid = k,
                     preProc = c("center", "scale"),
                     trControl = fitControl)

plot(model_knn)
```

## Gerando CSV a partir da predição usando os dados de teste
```{r}
prediction <- predict(model_knn, test)  
data_out <- data.frame(ID = test$sequencial_candidato, votos = prediction) 
data_out$ID <-as.character(data_out$ID)  
data_out %>% write_csv(path = "out.csv") 
prediction
```